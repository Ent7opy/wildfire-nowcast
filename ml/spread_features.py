"""Pipeline for assembling spread model input features."""

from __future__ import annotations

import logging
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Sequence

import numpy as np
import sqlalchemy as sa
import xarray as xr

from api.core.grid import GridSpec, GridWindow, get_grid_window_for_bbox
from api.db import get_engine
from api.fires.service import FireHeatmapWindow, get_fire_cells_heatmap, get_region_grid_spec
from api.terrain.window import TerrainWindow, load_terrain_window
from ml.spread.contract import DEFAULT_HORIZONS_HOURS, SpreadModelInput
from ml.weather_bias_correction import (
    WEATHER_BIAS_CORRECTOR_ENV,
    resolve_weather_bias_corrector_path,
    WeatherBiasCorrector,
 )

LOGGER = logging.getLogger(__name__)


@dataclass(frozen=True, slots=True)
class SpreadInputs:
    """Orchestrated input package for spread models."""

    grid: GridSpec
    window: GridWindow
    active_fires: FireHeatmapWindow
    weather_cube: xr.Dataset
    terrain: TerrainWindow
    forecast_reference_time: datetime
    horizons_hours: Sequence[int] = DEFAULT_HORIZONS_HOURS

    def to_model_input(self) -> SpreadModelInput:
        """Convert to the canonical SpreadModelInput expected by models."""
        return SpreadModelInput(
            grid=self.grid,
            window=self.window,
            active_fires=self.active_fires,
            weather_cube=self.weather_cube,
            terrain=self.terrain,
            forecast_reference_time=self.forecast_reference_time,
            horizons_hours=self.horizons_hours,
        )


def _require_tz_aware_utc(dt: datetime, *, field_name: str) -> datetime:
    """Require tz-aware datetime and normalize it to UTC.

    Weather ingest + spread heuristics expect times aligned to UTC and commonly use
    tz-naive UTC `datetime64[ns]` in xarray for selection.
    """
    if dt.tzinfo is None:
        raise ValueError(f"{field_name} must be timezone-aware (UTC recommended). Got tzinfo=None.")
    return dt.astimezone(timezone.utc)


def _as_datetime64_utc_naive(dt: datetime) -> np.datetime64:
    """Convert datetime to tz-naive UTC datetime64[ns] (ingest convention)."""
    if dt.tzinfo is not None:
        dt = dt.astimezone(timezone.utc).replace(tzinfo=None)
    return np.datetime64(dt, "ns")


def _same_window(a: GridWindow, b: GridWindow) -> bool:
    if (a.i0, a.i1, a.j0, a.j1) != (b.i0, b.i1, b.j0, b.j1):
        return False
    # Use strict equality when possible (they should be generated by the same grid math),
    # but allow tiny floating differences in tests/mocks.
    return bool(
        np.allclose(np.asarray(a.lat), np.asarray(b.lat), rtol=0.0, atol=1e-12)
        and np.allclose(np.asarray(a.lon), np.asarray(b.lon), rtol=0.0, atol=1e-12)
    )


def _assert_same_window(*, expected: GridWindow, actual: GridWindow, label: str) -> None:
    if not _same_window(expected, actual):
        raise ValueError(
            f"{label} window does not match requested AOI window. "
            f"expected={(expected.i0, expected.i1, expected.j0, expected.j1)} "
            f"actual={(actual.i0, actual.i1, actual.j0, actual.j1)}"
        )


def _get_latest_weather_run(
    ref_time: datetime,
    bbox: tuple[float, float, float, float],
) -> dict | None:
    """Find the latest completed weather run covering the AOI before or at ref_time."""
    min_lon, min_lat, max_lon, max_lat = bbox
    stmt = sa.text(
        """
        SELECT id, storage_path, run_time
        FROM weather_runs
        WHERE status = 'completed'
          AND run_time <= :ref_time
          AND COALESCE(bbox_min_lon, -180.0) <= :min_lon AND COALESCE(bbox_max_lon, 180.0) >= :max_lon
          AND COALESCE(bbox_min_lat, -90.0) <= :min_lat AND COALESCE(bbox_max_lat, 90.0) >= :max_lat
        ORDER BY run_time DESC, created_at DESC
        LIMIT 1
        """
    )
    with get_engine().connect() as conn:
        row = conn.execute(
            stmt,
            {
                "ref_time": ref_time,
                "min_lon": min_lon,
                "max_lon": max_lon,
                "min_lat": min_lat,
                "max_lat": max_lat,
            },
        ).mappings().first()
    return dict(row) if row else None


def _load_weather_cube(
    ref_time: datetime,
    window: GridWindow,
    horizons_hours: Sequence[int],
    bbox: tuple[float, float, float, float],
    *,
    weather_bias_corrector_path: Path | None = None,
) -> xr.Dataset:
    """Load and align weather data for the requested window and horizons."""
    run = _get_latest_weather_run(ref_time, bbox)

    if not run:
        LOGGER.warning(
            "No completed weather run found for ref_time=%s and bbox=%s; using calm fallback.",
            ref_time, bbox
        )
        return _create_fallback_weather(window, ref_time, horizons_hours)

    path = Path(run["storage_path"])
    # Resolve relative path if needed (mirroring inspect_weather_run.py pattern)
    if not path.is_absolute():
        # Assume relative to current working directory (project root)
        path = Path.cwd() / path

    if not path.exists():
        LOGGER.warning("Weather run %s file missing at %s; using calm fallback.", run["id"], path)
        return _create_fallback_weather(window, ref_time, horizons_hours)

    ds = None
    try:
        ds = xr.open_dataset(path)

        missing_coords = [c for c in ("lat", "lon", "time") if c not in ds.coords]
        if missing_coords:
            LOGGER.warning(
                "Weather dataset at %s missing required coord(s) %s; using fallback.",
                path,
                missing_coords,
            )
            return _create_fallback_weather(window, ref_time, horizons_hours)

        missing_vars = [v for v in ("u10", "v10") if v not in ds.data_vars]
        if missing_vars:
            LOGGER.warning(
                "Weather dataset at %s missing required var(s) %s; using fallback.",
                path,
                missing_vars,
            )
            return _create_fallback_weather(window, ref_time, horizons_hours)

        # 1) Align to AOI window coords.
        #
        # Weather ingest writes NetCDFs already interpolated onto the shared analysis grid.
        # Prefer exact label-based selection; fall back to nearest for robustness.
        try:
            ds_aligned = ds.sel(lat=window.lat, lon=window.lon)
        except Exception:
            LOGGER.info("Exact lat/lon selection failed for %s; falling back to nearest.", path)
            ds_aligned = ds.sel(lat=window.lat, lon=window.lon, method="nearest")

        # 2) Select requested time horizons (absolute times).
        target_times = [ref_time + timedelta(hours=int(h)) for h in horizons_hours]
        target_times_64 = [_as_datetime64_utc_naive(t) for t in target_times]

        ds_times = ds.coords["time"].values
        if len(ds_times) > 0:
            if target_times_64[0] < ds_times[0] or target_times_64[-1] > ds_times[-1]:
                LOGGER.warning(
                    "Requested horizons %s for ref_time %s are partially outside weather run %s range [%s, %s]",
                    list(horizons_hours),
                    ref_time,
                    run["id"],
                    ds_times[0],
                    ds_times[-1],
                )

        ds_final = ds_aligned.sel(time=target_times_64, method="nearest")
        ds_final = ds_final.assign_coords(
            time=target_times_64,
            lead_time_hours=("time", list(horizons_hours)),
        )

        # Ensure the caller doesn't hold an open file handle.
        ds_final = ds_final.load()

        # Optional: apply global bias correction (if configured).
        ds_final = _maybe_apply_weather_bias_correction(
            ds_final, weather_bias_corrector_path=weather_bias_corrector_path
        )
        return ds_final
    except Exception:
        LOGGER.exception("Failed to load/align weather dataset from %s; using fallback.", path)
        return _create_fallback_weather(window, ref_time, horizons_hours)
    finally:
        if ds is not None:
            try:
                ds.close()
            except Exception:  # pragma: no cover
                pass


def _create_fallback_weather(
    window: GridWindow,
    ref_time: datetime,
    horizons_hours: Sequence[int]
) -> xr.Dataset:
    """Create a zero-wind fallback weather cube."""
    target_times = [ref_time + timedelta(hours=h) for h in horizons_hours]
    target_times_64 = [np.datetime64(t.astimezone(timezone.utc).replace(tzinfo=None), "ns") for t in target_times]

    shape = (len(target_times_64), len(window.lat), len(window.lon))

    coords = {
        "time": target_times_64,
        "lat": window.lat,
        "lon": window.lon,
        "lead_time_hours": ("time", list(horizons_hours))
    }

    return xr.Dataset(
        data_vars={
            "u10": (("time", "lat", "lon"), np.zeros(shape, dtype=np.float32)),
            "v10": (("time", "lat", "lon"), np.zeros(shape, dtype=np.float32)),
            "t2m": (("time", "lat", "lon"), np.full(shape, np.nan, dtype=np.float32)),
            "rh2m": (("time", "lat", "lon"), np.full(shape, np.nan, dtype=np.float32)),
        },
        coords=coords
    )

def _maybe_apply_weather_bias_correction(
    ds: xr.Dataset, *, weather_bias_corrector_path: Path | None = None
) -> xr.Dataset:
    """Apply a bias corrector if configured by arg or env var."""
    resolved = resolve_weather_bias_corrector_path(weather_bias_corrector_path, env_var=WEATHER_BIAS_CORRECTOR_ENV)
    if resolved is None:
        return ds
    if not resolved.exists():
        LOGGER.warning(
            "Weather bias corrector path does not exist (%s=%s); skipping correction.",
            WEATHER_BIAS_CORRECTOR_ENV,
            resolved,
        )
        return ds

    try:
        corrector = WeatherBiasCorrector.load_json(resolved)
        LOGGER.info(
            "Applied weather bias correction",
            extra={
                "corrector_path": str(resolved),
                "format_version": int(corrector.to_dict().get("format_version", -1)),
                "variables": sorted(list(getattr(corrector, "corrections", {}).keys())),
            },
        )
        out = corrector.apply(ds, inplace=False)
        # Attach lightweight provenance for downstream logging/persistence.
        try:
            out.attrs = dict(out.attrs or {})
            out.attrs["weather_bias_corrected"] = True
            out.attrs["weather_bias_corrector_path"] = str(resolved)
        except Exception:  # pragma: no cover
            pass
        return out
    except Exception:
        LOGGER.exception("Failed to load/apply weather bias corrector from %s; using uncorrected weather.", resolved)
        return ds


def build_spread_inputs(
    region_name: str | None,
    bbox: tuple[float, float, float, float],
    forecast_reference_time: datetime,
    *,
    horizons_hours: Sequence[int] = DEFAULT_HORIZONS_HOURS,
    fire_lookback_hours: int = 24,
    include_dem: bool = True,
    weight_by_denoised_score: bool = True,
    weather_bias_corrector_path: Path | None = None,
) -> SpreadInputs:
    """Assemble all required inputs for a spread model prediction.

    Parameters
    ----------
    region_name : str | None
        The name of the region (determines the analysis grid). If None, grid is created from bbox
        and terrain is set to empty (for location-based forecasting without pre-defined regions).
    bbox : tuple[float, float, float, float]
        The AOI bounding box (min_lon, min_lat, max_lon, max_lat).
    forecast_reference_time : datetime
        The T=0 time for the forecast.
    horizons_hours : Sequence[int], optional
        The forecast horizons in hours from reference time.
    fire_lookback_hours : int, optional
        How far back from reference time to look for active fires.
    include_dem : bool, optional
        Whether to include elevation in the terrain features.
    weight_by_denoised_score : bool, optional
        Whether to weight fire cells by their denoised score (default: True).

    Returns
    -------
    SpreadInputs
        The assembled and aligned inputs.
    """
    forecast_reference_time = _require_tz_aware_utc(
        forecast_reference_time, field_name="forecast_reference_time"
    )

    # 1. Resolve grid and window
    # If region_name is None, create grid from bbox (for location-based forecasting)
    if region_name is None:
        min_lon, min_lat, max_lon, max_lat = bbox
        grid = GridSpec.from_bbox(
            lat_min=min_lat,
            lat_max=max_lat,
            lon_min=min_lon,
            lon_max=max_lon,
        )
    else:
        grid = get_region_grid_spec(region_name)
    window = get_grid_window_for_bbox(grid, bbox, clip=True)

    # 2. Load fires
    fire_start = forecast_reference_time - timedelta(hours=fire_lookback_hours)
    try:
        # If region_name is None, we need to create fire heatmap manually using the grid
        if region_name is None:
            from api.fires.repo import list_fire_detections_bbox_time
            from api.fires.grid_mapping import fires_to_indices, aggregate_indices_to_grid

            cols = ["lat", "lon"]
            if weight_by_denoised_score:
                cols.append("denoised_score")

            detections = list_fire_detections_bbox_time(
                bbox=bbox,
                start_time=fire_start,
                end_time=forecast_reference_time,
                columns=cols,
                include_noise=False,
            )
            mapped = fires_to_indices(detections, grid, drop_outside=True)

            if not mapped:
                heatmap = aggregate_indices_to_grid(
                    i=np.asarray([], dtype=int),
                    j=np.asarray([], dtype=int),
                    shape=(window.lat.size, window.lon.size),
                    mode="max" if weight_by_denoised_score else "presence",
                )
            else:
                i = np.asarray([r["i"] for r in mapped], dtype=int)
                j = np.asarray([r["j"] for r in mapped], dtype=int)
                # Adjust indices to window-relative
                i_window = i - window.i0
                j_window = j - window.j0
                # Filter to window bounds
                in_window = (i_window >= 0) & (i_window < window.lat.size) & (j_window >= 0) & (j_window < window.lon.size)
                i_window = i_window[in_window]
                j_window = j_window[in_window]

                if weight_by_denoised_score:
                    # Handle NULL denoised_score values: treat unscored detections as full-weight (1.0)
                    # to avoid NaN poisoning in numpy arrays (same pattern as api/fires/service.py)
                    values = np.asarray([(r.get("denoised_score") if r.get("denoised_score") is not None else 1.0) for r in mapped], dtype=np.float32)
                    values = values[in_window]
                    heatmap = aggregate_indices_to_grid(
                        i=i_window,
                        j=j_window,
                        shape=(window.lat.size, window.lon.size),
                        mode="max",
                        values=values,
                    )
                else:
                    heatmap = aggregate_indices_to_grid(
                        i=i_window,
                        j=j_window,
                        shape=(window.lat.size, window.lon.size),
                        mode="presence",
                    )

            from api.fires.service import FireHeatmapWindow
            fires = FireHeatmapWindow(
                grid=grid,
                window=window,
                heatmap=heatmap,
                points=None,
            )
        else:
            fires = get_fire_cells_heatmap(
                region_name=region_name,
                bbox=bbox,
                start_time=fire_start,
                end_time=forecast_reference_time,
                weight_by_denoised_score=weight_by_denoised_score,
                mode="max" if weight_by_denoised_score else "presence",
                clip=True,
            )
    except Exception as e:
        raise RuntimeError(
            f"Failed to load fire heatmap for region={region_name!r} bbox={bbox!r} "
            f"start_time={fire_start!r} end_time={forecast_reference_time!r}"
        ) from e
    if fires.grid != grid:
        raise ValueError("Fire heatmap grid does not match region grid spec.")
    _assert_same_window(expected=window, actual=fires.window, label="active_fires")

    # 3. Load terrain (optional - create empty terrain if region_name is None or terrain unavailable)
    if region_name is None:
        # Create empty terrain for location-based forecasting
        LOGGER.info("No region_name provided; using empty terrain (terrain features disabled)")
        from api.terrain.window import TerrainWindow
        terrain = TerrainWindow(
            window=window,
            slope=np.zeros((window.lat.size, window.lon.size), dtype=np.float32),
            aspect=np.zeros((window.lat.size, window.lon.size), dtype=np.float32),
            elevation=np.zeros((window.lat.size, window.lon.size), dtype=np.float32) if include_dem else None,
            valid_data_mask=np.ones((window.lat.size, window.lon.size), dtype=bool),
            aoi_mask=None,
        )
    else:
        try:
            terrain = load_terrain_window(
                region_name=region_name,
                bbox=bbox,
                include_dem=include_dem,
                clip=True,
            )
        except Exception as e:
            LOGGER.warning(
                f"Failed to load terrain for region={region_name!r} bbox={bbox!r}; using empty terrain",
                exc_info=e
            )
            # Fallback to empty terrain if region exists but terrain load fails
            from api.terrain.window import TerrainWindow
            terrain = TerrainWindow(
                window=window,
                slope=np.zeros((window.lat.size, window.lon.size), dtype=np.float32),
                aspect=np.zeros((window.lat.size, window.lon.size), dtype=np.float32),
                elevation=np.zeros((window.lat.size, window.lon.size), dtype=np.float32) if include_dem else None,
                valid_data_mask=np.ones((window.lat.size, window.lon.size), dtype=bool),
                aoi_mask=None,
            )
    _assert_same_window(expected=window, actual=terrain.window, label="terrain")

    # 4. Load weather
    weather = _load_weather_cube(
        ref_time=forecast_reference_time,
        window=window,
        horizons_hours=horizons_hours,
        bbox=bbox,
        weather_bias_corrector_path=weather_bias_corrector_path,
    )
    # Basic contract checks for downstream models.
    if not all(d in weather.dims for d in ("time", "lat", "lon")):
        raise ValueError(f"weather_cube must include dims time/lat/lon; got dims={dict(weather.dims)!r}")
    if int(weather.sizes.get("lat", 0)) != int(window.lat.size) or int(weather.sizes.get("lon", 0)) != int(
        window.lon.size
    ):
        raise ValueError(
            "weather_cube spatial dims do not match window. "
            f"weather(lat,lon)=({int(weather.sizes.get('lat', 0))},{int(weather.sizes.get('lon', 0))}) "
            f"window=({int(window.lat.size)},{int(window.lon.size)})"
        )
    if "lat" in weather.coords and not np.allclose(
        np.asarray(weather.coords["lat"].values), np.asarray(window.lat), rtol=0.0, atol=1e-12
    ):
        raise ValueError("weather_cube.lat does not match window.lat")
    if "lon" in weather.coords and not np.allclose(
        np.asarray(weather.coords["lon"].values), np.asarray(window.lon), rtol=0.0, atol=1e-12
    ):
        raise ValueError("weather_cube.lon does not match window.lon")

    return SpreadInputs(
        grid=grid,
        window=window,
        active_fires=fires,
        weather_cube=weather,
        terrain=terrain,
        forecast_reference_time=forecast_reference_time,
        horizons_hours=horizons_hours,
    )

