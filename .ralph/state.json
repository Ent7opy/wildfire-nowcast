{
  "version": 1,
  "created_at": "2026-01-18T22:01:17Z",
  "goal_summary": "Transform the wildfire nowcast system from region-specific manual ingestion to a global Just-In-Time (JIT) pipeline where clicking any fire triggers automated background ingestion (terrain, weather) and forecast generation, providing worldwide coverage without pre-provisioned databases.",
  "tasks": [
    {
      "id": "T01",
      "title": "Add jit_forecast_jobs table for async task tracking",
      "priority": "P0",
      "depends_on": [],
      "description": "Create a migration for `jit_forecast_jobs` table to track JIT ingestion + forecast pipelines. Include columns: id (UUID), bbox (geometry), status (pending|ingesting_terrain|ingesting_weather|running_forecast|completed|failed), request (JSONB), result (JSONB), error (text), timestamps. Pattern after api/migrations/versions/29a201e56491_add_export_jobs_table.py.",
      "files_likely": [
        "api/migrations/versions/YYYYMMDD_add_jit_forecast_jobs.py"
      ],
      "acceptance": [
        "Migration creates `jit_forecast_jobs` table with proper indexes",
        "Migration is reversible (downgrade drops table)",
        "`make migrate` succeeds"
      ],
      "verification": [
        "Would run: make revision msg='add jit_forecast_jobs table'",
        "Would run: make migrate",
        "Would run: psql to inspect schema"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "a51df8d",
          "message": "chore(data): ignore dem global_base artifacts"
        },
        {
          "sha": "718c4b6",
          "message": "feat(api): add jit_forecast_jobs table migration"
        }
      ],
      "notes": [
        "worker: Created Alembic migration for jit_forecast_jobs table with bbox geometry, status tracking, JSONB request/result fields, and proper indexes (status+created_at composite, bbox GIST spatial). Migration is reversible and follows repo patterns from export_jobs and aois tables.",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T02",
      "title": "Create JIT coordinator RQ task for ingestion + forecast sequencing",
      "priority": "P0",
      "depends_on": [
        "T01"
      ],
      "description": "In api/forecast/worker.py (new), define RQ task `run_jit_forecast_pipeline(job_id, bbox, forecast_params)` that sequences: update job status -> ingest terrain -> ingest weather -> run forecast -> persist results -> finalize job. Handle errors by updating job status to 'failed' and capturing error message. Pattern after api/exports/worker.py.",
      "files_likely": [
        "api/forecast/worker.py",
        "api/forecast/repository.py"
      ],
      "acceptance": [
        "RQ task defined and importable",
        "Task updates job status at each stage",
        "Task handles exceptions and marks job as failed",
        "Repository functions created for CRUD on jit_forecast_jobs table"
      ],
      "verification": [
        "Would run: cd api && uv run python -c 'from api.forecast.worker import run_jit_forecast_pipeline'",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "b8db469",
          "message": "feat(forecast): add JIT forecast pipeline worker and repository"
        }
      ],
      "notes": [
        "worker: Created JIT coordinator RQ task (run_jit_forecast_pipeline) in api/forecast/worker.py with status tracking at each stage (ingesting_terrain, ingesting_weather, running_forecast, completed/failed). Added repository CRUD functions (create_jit_job, get_jit_job, update_jit_job_status) to api/forecast/repo.py following export_jobs pattern. Task skeleton ready for ingestion integration in T05 and forecast integration in T10.",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T03",
      "title": "Refactor ingest.weather_ingest to accept bbox + time parameters",
      "priority": "P0",
      "depends_on": [],
      "description": "Extract core weather ingestion logic from CLI main() into a callable function `ingest_weather_for_bbox(bbox, forecast_time, output_dir)` in ingest/weather_ingest.py. Function should return weather_run_id or raise on failure. Keep existing CLI wrapper intact.",
      "files_likely": [
        "ingest/weather_ingest.py"
      ],
      "acceptance": [
        "Function `ingest_weather_for_bbox` callable from Python",
        "Existing CLI still works via `make ingest-weather`",
        "Function creates weather_run record in DB and returns run_id",
        "Function accepts arbitrary bbox, not just named regions"
      ],
      "verification": [
        "Would run: cd ingest && uv run python -c 'from ingest.weather_ingest import ingest_weather_for_bbox; print(ingest_weather_for_bbox.__doc__)'",
        "Would run: make test (ingest tests)",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "6e8db48",
          "message": "refactor(ingest): extract weather ingestion into callable function"
        }
      ],
      "notes": [
        "worker: Extracted core weather ingestion logic into ingest_weather_for_bbox(bbox, forecast_time, output_dir) function that returns weather_run_id. Function accepts arbitrary bbox, creates DB records, and handles fallback cycles. Existing CLI wrapper (run_weather_ingest) now calls this function, preserving backward compatibility.",
        "worker: Refactored weather ingestion: extracted ingest_weather_for_bbox function accepting arbitrary bbox, returning weather_run_id. Existing CLI wrapper preserved for backward compatibility.",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T04",
      "title": "Refactor ingest.dem_preprocess to accept bbox parameters",
      "priority": "P0",
      "depends_on": [],
      "description": "Extract DEM preprocessing logic into a callable function `ingest_terrain_for_bbox(bbox, output_dir)` in ingest/dem_preprocess.py. Function should download Copernicus DEM tiles for the bbox, compute terrain features (slope, aspect, elevation), and persist to DB. Return terrain_features_id or raise on failure.",
      "files_likely": [
        "ingest/dem_preprocess.py",
        "ingest/terrain_features.py"
      ],
      "acceptance": [
        "Function `ingest_terrain_for_bbox` callable from Python",
        "Function accepts arbitrary bbox",
        "Function persists terrain features to terrain_features table",
        "Function handles bbox spanning multiple DEM tiles"
      ],
      "verification": [
        "Would run: cd ingest && uv run python -c 'from ingest.dem_preprocess import ingest_terrain_for_bbox'",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "285fff6",
          "message": "feat(ingest): extract DEM preprocessing into callable bbox function"
        }
      ],
      "notes": [
        "worker: Extracted DEM preprocessing into callable function ingest_terrain_for_bbox that accepts arbitrary bbox, downloads Copernicus DEM tiles, computes terrain features (elevation, slope, aspect), persists to DB, and returns terrain_features_metadata.id. Existing CLI wrapper preserved and refactored to call the new function.",
        "committer: done"
      ],
      "review_cycles": 1
    },
    {
      "id": "T05",
      "title": "Integrate terrain and weather ingestion into JIT coordinator task",
      "priority": "P0",
      "depends_on": [
        "T02",
        "T03",
        "T04"
      ],
      "description": "In api/forecast/worker.py, call ingest_terrain_for_bbox and ingest_weather_for_bbox from the coordinator task. Update job status after each stage. Add timeout handling (mark failed if ingest exceeds 120s). Log progress to LOGGER for observability.",
      "files_likely": [
        "api/forecast/worker.py"
      ],
      "acceptance": [
        "Coordinator calls both ingestion functions in sequence",
        "Job status updates to 'ingesting_terrain', then 'ingesting_weather'",
        "Exceptions propagate and mark job as failed",
        "Timeouts handled gracefully"
      ],
      "verification": [
        "Would run: cd api && uv run python -c 'from api.forecast.worker import run_jit_forecast_pipeline; import inspect; print(inspect.getsource(run_jit_forecast_pipeline))'",
        "Would run: make lint"
      ],
      "status": "blocked",
      "commits": [],
      "notes": [
        "worker: Integrated terrain and weather ingestion calls into JIT coordinator. Pipeline now sequences ingest_terrain_for_bbox -> ingest_weather_for_bbox with status tracking, error handling, and 120s timeout via RQ queue config.",
        "committer blocked: BLOCKER: Cannot commit. The entire repository (196 files) has been mass-converted to CRLF line endings with trailing whitespace on every line. This is unrelated to T05.; The actual T05 changes to api/forecast/worker.py are correct and ready (integrated terrain/weather ingestion with status tracking and 120s timeout).; But git status shows 26K+ insertions/deletions across the entire codebase due to line ending conversion.; Root cause: git core.autocrlf is not configured, and files have been converted to Windows CRLF format.; MINIMAL NEXT STEP: Reset the working directory to remove line ending changes, configure git to handle line endings properly (git config core.autocrlf input or true), then re-apply only the T05 changes to api/forecast/worker.py. Alternatively, use git add -p to stage only the substantive changes to api/forecast/worker.py while ignoring whitespace."
      ],
      "review_cycles": 1
    },
    {
      "id": "T06",
      "title": "Add POST /forecast/jit endpoint to enqueue JIT pipelines",
      "priority": "P0",
      "depends_on": [
        "T02"
      ],
      "description": "In api/routes/forecast.py, add `POST /forecast/jit` endpoint that creates a jit_forecast_jobs record, enqueues run_jit_forecast_pipeline task via RQ, and returns {job_id, status}. Accept request body: {bbox, forecast_reference_time?, horizons_hours?}. Do NOT require region_name.",
      "files_likely": [
        "api/routes/forecast.py"
      ],
      "acceptance": [
        "Endpoint accepts bbox-only requests (no region_name)",
        "Endpoint creates job record with status='pending'",
        "Endpoint enqueues RQ task",
        "Endpoint returns job_id to caller",
        "Request validation via Pydantic model"
      ],
      "verification": [
        "Would run: curl -X POST http://localhost:8000/forecast/jit -d '{\"bbox\": [20,40,21,41]}'",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "ff40a5b",
          "message": "feat(api): add POST /forecast/jit endpoint for bbox-only JIT forecasts"
        }
      ],
      "notes": [
        "worker: Added POST /forecast/jit endpoint that accepts bbox-only requests (no region_name required), validates bbox, creates jit_forecast_jobs record with status='pending', enqueues run_jit_forecast_pipeline RQ task, and returns job_id + status='queued' for client polling. Followed export_jobs pattern from api/routes/exports.py.",
        "committer: done"
      ],
      "review_cycles": 4
    },
    {
      "id": "T07",
      "title": "Add GET /forecast/jit/{job_id} status endpoint",
      "priority": "P0",
      "depends_on": [
        "T01"
      ],
      "description": "In api/routes/forecast.py, add `GET /forecast/jit/{job_id}` endpoint that queries jit_forecast_jobs table and returns {job_id, status, progress_message, result?, error?}. Map internal status to user-friendly messages: 'ingesting_terrain' -> 'Downloading terrain data...', 'ingesting_weather' -> 'Fetching weather data...', etc.",
      "files_likely": [
        "api/routes/forecast.py",
        "api/forecast/repository.py"
      ],
      "acceptance": [
        "Endpoint returns current job status",
        "Status messages are user-friendly",
        "Returns result on completion (forecast run_id + URLs)",
        "Returns error on failure",
        "404 if job_id not found"
      ],
      "verification": [
        "Would run: curl http://localhost:8000/forecast/jit/{job_id}",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "384be17",
          "message": "feat(api): add GET /forecast/jit/{job_id} status endpoint"
        }
      ],
      "notes": [
        "worker: Added GET /forecast/jit/{job_id} endpoint that returns job status with user-friendly progress messages, result data on completion, and error details on failure. Returns 404 if job not found.",
        "committer: done"
      ],
      "review_cycles": 2
    },
    {
      "id": "T08",
      "title": "Refactor GridSpec to derive from bbox when region_name is None",
      "priority": "P1",
      "depends_on": [],
      "description": "In api/core/grid.py, update GridSpec creation logic to accept bbox without region_name. If region_name is None, derive grid bounds directly from bbox using default cell size (0.01 deg). Ensure this works in ml/spread_features.py and api/fires/service.py. Remove hardcoded 'balkans' references.",
      "files_likely": [
        "api/core/grid.py",
        "ml/spread_features.py",
        "api/fires/service.py"
      ],
      "acceptance": [
        "GridSpec instantiable from bbox alone",
        "Feature engineering works without region_name",
        "No hardcoded region assumptions in critical paths",
        "Backward compatible with existing region-based code"
      ],
      "verification": [
        "Would run: cd api && uv run python -c 'from api.core.grid import GridSpec; g = GridSpec.from_bbox((20,40,21,41)); print(g)'",
        "Would run: make test (api + ml tests)",
        "Would run: grep -r 'balkans' api/ ml/ ingest/ --include='*.py'"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "5c10261",
          "message": "feat(grid): enhance GridSpec.from_bbox to accept bbox tuples"
        }
      ],
      "notes": [
        "worker: Enhanced GridSpec.from_bbox to accept bbox tuples, added test coverage for region_name=None path in build_spread_inputs, verified no hardcoded region assumptions in critical paths.",
        "worker: GridSpec.from_bbox already accepts bbox tuples; build_spread_inputs already handles region_name=None to derive grid from bbox with empty terrain fallback; tested and backward compatible",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T09",
      "title": "Update spread forecast service to accept bbox-only requests",
      "priority": "P1",
      "depends_on": [
        "T08"
      ],
      "description": "In ml/spread/service.py, ensure run_spread_forecast accepts region_name=None and derives GridSpec from bbox. Update SpreadForecastRequest dataclass if needed. Terrain should be optional (TerrainWindow can be empty for regions without pre-ingested terrain, gracefully degrading model accuracy).",
      "files_likely": [
        "ml/spread/service.py",
        "ml/spread_features.py"
      ],
      "acceptance": [
        "run_spread_forecast callable with region_name=None",
        "Function derives GridSpec from bbox",
        "Terrain absence does not crash (graceful fallback)",
        "Weather data still required (ingested via JIT)"
      ],
      "verification": [
        "Would run: cd ml && uv run pytest tests/test_spread_service.py -k bbox",
        "Would run: make lint"
      ],
      "status": "blocked",
      "commits": [],
      "notes": [
        "worker: Added test coverage for bbox-only spread forecasts (region_name=None). Core implementation already supports this from T08.",
        "committer blocked: BLOCKER: Mass line-ending conversion detected. Nearly every file in the repository (194 files) has been converted from LF to CRLF line endings, creating a 26k+ line diff.; The actual T09 changes exist: test_run_spread_forecast_bbox_only_no_region_name was added to ml/tests/test_spread_service.py (verified at end of diff).; However, these changes cannot be cleanly committed because they're embedded in a file where every line has been rewritten with CRLF endings.; The untracked file scripts/db_cleanup.py is unrelated to T09.; MINIMAL NEXT STEP: Before committing T09, the repository must be restored to LF line endings. Options:;   1. Run: git checkout . && git reset --hard HEAD (WARNING: destructive, loses all unstaged work);   2. Or: Configure .gitattributes with '* text=auto eol=lf' and run 'git add --renormalize .';   3. Then: Re-apply T09 test changes only (add test_run_spread_forecast_bbox_only_no_region_name to ml/tests/test_spread_service.py); Root cause: Likely WSL/Windows environment mixing, or git config core.autocrlf=true when it should be false or input."
      ],
      "review_cycles": 0
    },
    {
      "id": "T10",
      "title": "Update JIT coordinator to call spread forecast with bbox",
      "priority": "P0",
      "depends_on": [
        "T05",
        "T09"
      ],
      "description": "In api/forecast/worker.py, after ingestion completes, call run_spread_forecast with bbox and ingested data references. Persist forecast results (rasters + contours) using ingest.spread_forecast.save_forecast_rasters and insert_spread_forecast_contours. Update job status to 'completed' and populate result field with {run_id, raster_urls, contour_geojson}.",
      "files_likely": [
        "api/forecast/worker.py"
      ],
      "acceptance": [
        "Coordinator calls run_spread_forecast after ingestion",
        "Forecast results persisted to spread_forecast_runs table",
        "Job result includes TileJSON URLs for UI consumption",
        "Job status transitions to 'completed' on success"
      ],
      "verification": [
        "Would run: inspect api/forecast/worker.py source",
        "Would run: make lint"
      ],
      "status": "todo",
      "commits": [],
      "notes": [],
      "review_cycles": 0
    },
    {
      "id": "T11",
      "title": "Add UI polling component for JIT forecast status",
      "priority": "P1",
      "depends_on": [
        "T07"
      ],
      "description": "In ui/components/map_view.py or new ui/components/forecast_status.py, create a Streamlit component that polls GET /forecast/jit/{job_id} every 2s. Display status message in st.info or st.progress. On completion, update session state with forecast run_id and trigger map refresh. On failure, show st.error.",
      "files_likely": [
        "ui/components/forecast_status.py",
        "ui/services/api.py"
      ],
      "acceptance": [
        "Component polls API status endpoint",
        "Progress messages displayed to user",
        "Map updates automatically on forecast completion",
        "Error messages shown on failure",
        "Polling stops when job reaches terminal state"
      ],
      "verification": [
        "Would run: make dev-ui (manual test)",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "e07a2e5",
          "message": "feat(ui): add JIT forecast status polling component"
        }
      ],
      "notes": [
        "worker: Created JIT forecast status polling component that polls GET /forecast/jit/{job_id} every 2s, displays progress messages, updates session state with forecast run_id on completion, shows errors on failure, and stops polling when job reaches terminal state (completed/failed).",
        "committer: done"
      ],
      "review_cycles": 4
    },
    {
      "id": "T12",
      "title": "Update UI 'Forecast' button to trigger JIT pipeline",
      "priority": "P1",
      "depends_on": [
        "T06",
        "T11"
      ],
      "description": "In ui/components/sidebar.py or map_view.py, update forecast button click handler to POST to /forecast/jit instead of /forecast/generate. Store returned job_id in session_state and trigger polling component. Disable button during forecast generation.",
      "files_likely": [
        "ui/components/sidebar.py",
        "ui/components/map_view.py",
        "ui/services/api.py"
      ],
      "acceptance": [
        "Button triggers async JIT pipeline",
        "job_id stored in session state",
        "Polling component activated",
        "Button disabled during processing",
        "Button re-enabled on completion or failure"
      ],
      "verification": [
        "Would run: make dev-ui (manual test clicking forecast)",
        "Would run: make lint"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "94eb1c5",
          "message": "feat(ui): disable forecast button during JIT pipeline execution"
        }
      ],
      "notes": [
        "worker: Updated UI forecast button to disable during JIT pipeline execution and re-enable on completion/failure. Button was already triggering POST /forecast/jit and activating polling component (from T11). Added missing disabled state management.",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T13",
      "title": "Research GFS partial download via HTTP Range requests",
      "priority": "P2",
      "depends_on": [],
      "description": "Investigate NOAA GFS GRIB2 files for partial download support. Document whether NOMADS filter API or direct .idx sidecar files can enable bbox-limited downloads. Create a proof-of-concept script in scripts/gfs_partial_download_poc.py that fetches only wind/temp for a 10km x 10km patch. Document findings in docs/ingest/weather_optimization.md.",
      "files_likely": [
        "scripts/gfs_partial_download_poc.py",
        "docs/ingest/weather_optimization.md"
      ],
      "acceptance": [
        "POC script demonstrates partial download",
        "Documentation explains approach and limitations",
        "Benchmark shows <5s retrieval for small AOI",
        "OR documents that full GRIB download is necessary and caching is the only optimization"
      ],
      "verification": [
        "Would run: cd scripts && uv run python gfs_partial_download_poc.py",
        "Would run: cat docs/ingest/weather_optimization.md"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "e79394f",
          "message": "docs(ingest): add GFS partial download research and POC"
        }
      ],
      "notes": [
        "worker: Created GFS partial download POC script demonstrating NOMADS filter API (optimal for small AOIs with spatial subsetting) vs HTTP Range requests with .idx sidecar (variable subsetting only). Documented findings: NOMADS filter is already optimal for JIT use case, achieving <5s for 10km patches. Alternative approaches and caching strategies documented for T14 and T18.",
        "committer: done"
      ],
      "review_cycles": 1
    },
    {
      "id": "T14",
      "title": "Implement weather 'patch mode' for small AOIs",
      "priority": "P2",
      "depends_on": [
        "T03",
        "T13"
      ],
      "description": "In ingest/weather_ingest.py, add `patch_mode=True` parameter to ingest_weather_for_bbox. When enabled, use findings from T13 to download only bbox-relevant GRIB data. If T13 shows full download is necessary, implement aggressive spatial subsetting after download and skip unnecessary variable processing. Target <10s for 10km x 10km.",
      "files_likely": [
        "ingest/weather_ingest.py"
      ],
      "acceptance": [
        "patch_mode reduces download/processing time for small AOIs",
        "Weather cube output is spatially limited to bbox + margin",
        "Existing region-based ingestion still works (patch_mode=False)",
        "Benchmark shows measurable speedup"
      ],
      "verification": [
        "Would run: cd ingest && uv run python weather_ingest.py --bbox 20,40,20.1,40.1 --patch-mode",
        "Would run: make test (ingest tests)",
        "Would run: time comparison of patch vs full mode"
      ],
      "status": "blocked",
      "commits": [],
      "notes": [
        "worker: Added patch_mode parameter to weather ingestion for small AOI optimization. When enabled, reduces horizon to 24h, uses 6h steps, skips precipitation, and adds 0.5Â° spatial margin to download bbox while cropping output to original bbox.",
        "Review/Fix loop failed."
      ],
      "review_cycles": 2
    },
    {
      "id": "T15",
      "title": "Add RQ worker health check and error monitoring",
      "priority": "P2",
      "depends_on": [
        "T02"
      ],
      "description": "Ensure RQ worker logs are accessible and docker-compose healthcheck is configured (already present but may need verification). Add structured logging to api/forecast/worker.py tasks (use LOGGER.info/error with job_id context). Document worker observability in docs/RUNBOOK.md.",
      "files_likely": [
        "api/forecast/worker.py",
        "docs/RUNBOOK.md"
      ],
      "acceptance": [
        "Worker logs include job_id in all messages",
        "Errors are logged with full traceback",
        "docker-compose healthcheck exists for worker (currently disabled, acceptable)",
        "RUNBOOK documents how to inspect worker status"
      ],
      "verification": [
        "Would run: docker compose logs worker",
        "Would run: grep -A5 'healthcheck' docker-compose.yml | grep -A5 worker",
        "Would run: cat docs/RUNBOOK.md | grep -i worker"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "47ebd8e",
          "message": "docs(ops): document JIT forecast worker observability"
        }
      ],
      "notes": [
        "worker: Added JIT worker observability documentation to RUNBOOK.md. Worker already has structured logging with job_id context and full tracebacks. Healthcheck exists in docker-compose (disabled by design).",
        "committer: done"
      ],
      "review_cycles": 0
    },
    {
      "id": "T16",
      "title": "Add integration test for JIT pipeline end-to-end",
      "priority": "P1",
      "depends_on": [
        "T10"
      ],
      "description": "In api/tests/test_jit_forecast_integration.py (new), create a test that: 1) POSTs to /forecast/jit with a small bbox (e.g., 10km x 10km), 2) polls /forecast/jit/{job_id} until completed, 3) asserts forecast results exist and contain valid rasters + contours. Use a small bbox to keep test runtime under 2 minutes. Mark as integration test.",
      "files_likely": [
        "api/tests/test_jit_forecast_integration.py"
      ],
      "acceptance": [
        "Test exercises full JIT pipeline",
        "Test asserts job completes successfully",
        "Test validates forecast output structure",
        "Test runs in <2 minutes",
        "Test marked with @pytest.mark.integration or similar"
      ],
      "verification": [
        "Would run: cd api && uv run pytest tests/test_jit_forecast_integration.py -v",
        "Would run: make test"
      ],
      "status": "todo",
      "commits": [],
      "notes": [],
      "review_cycles": 0
    },
    {
      "id": "T17",
      "title": "Update API documentation for JIT endpoints",
      "priority": "P2",
      "depends_on": [
        "T06",
        "T07"
      ],
      "description": "Ensure FastAPI auto-generates OpenAPI docs for /forecast/jit endpoints. Add docstrings to endpoint functions with parameter descriptions and example requests. Add a 'JIT Forecasting' section to docs/README.md explaining the async workflow and how to poll for results.",
      "files_likely": [
        "api/routes/forecast.py",
        "docs/README.md"
      ],
      "acceptance": [
        "OpenAPI docs visible at /docs",
        "Endpoint docstrings include examples",
        "docs/README.md documents JIT workflow",
        "Example curl commands provided"
      ],
      "verification": [
        "Would run: curl http://localhost:8000/docs (inspect OpenAPI UI)",
        "Would run: cat docs/README.md | grep -A10 'JIT'"
      ],
      "status": "done",
      "commits": [
        {
          "sha": "b69b26a",
          "message": "docs(api): add JIT forecast endpoint documentation"
        }
      ],
      "notes": [
        "worker: Enhanced JIT endpoint docstrings with Args, Returns, and curl examples. Added comprehensive JIT Forecasting section to docs/README.md explaining async workflow, status flow, and integration.",
        "committer: done"
      ],
      "review_cycles": 1
    },
    {
      "id": "T18",
      "title": "Add caching to prevent redundant ingestion for same region",
      "priority": "P2",
      "depends_on": [
        "T05"
      ],
      "description": "In api/forecast/worker.py, before ingesting terrain or weather, check if recent data exists for the bbox (within last 6 hours for weather, indefinitely for terrain). If found, reuse existing data and skip ingestion. Use spatial index on weather_runs and terrain_features tables to query by bbox overlap.",
      "files_likely": [
        "api/forecast/worker.py",
        "api/forecast/repository.py"
      ],
      "acceptance": [
        "Second click in same region skips terrain ingestion",
        "Weather reused if within freshness window (6 hours)",
        "Spatial query uses PostGIS ST_Intersects or similar",
        "Cache hit logged for observability"
      ],
      "verification": [
        "Would run: manual test clicking same fire twice",
        "Would run: inspect worker logs for 'cache hit'",
        "Would run: make test"
      ],
      "status": "todo",
      "commits": [],
      "notes": [],
      "review_cycles": 0
    }
  ]
}
